# 4주차
* 회귀진단의 목적
    * 데이터 분석
    * 이상 검출
## 4.1 단순선형회귀
* 정의: 두 변수가 어떤 관계인지 보여주는 방법 중 하나
    * 상관관계는 두 변수의 전체적인 관련 강도를 측정하는 것 
* 용어
    * 적합값: 회귀선으로부터 얻은 추정치로, 햇(^)을 문자 위에 표기하여 나타냄
    * 잔차: 관측값과 적합값의 차이
    * 회귀선: 잔차제곱합(RSS)를 최소화하는 선 
    * OLS: 최소제곱회귀

## 4.2 다중선형회귀
* 용어
    * 제곱근평균제곱오차(RMSE): 예측값과 실제값 차이의 표준편차. 예측 모델이 실제 데이터를 얼마나 잘 예측했는지를 수치로 나타냄.
    * 잔차 표준오차(RSE): 자유도에 따라 보정됨. (계산 시 n-1 고려)
    * t 통계량: 귀무가설 (예측계수 = 0), 대립가설 (예측계수 != 0)를 가지고 유의 or not 판단
* 해석
```
R-squared: 0.952   ⓵
Adj. R-squared: 0.936 ⓵ 
F-statistic:    59.41 ⓶
Prob (F-statistic): 0.00454 ⓶ 

⓷           coef   std err   t        P>|t|	
Intercept    -27.8  18.331   -1.517    0.227	
X            0.426  0.055    7.708     0.005
```
⓵ R-squared (결정계수) & Adjusted R-squared (수정된 결정계수)
* R-squared = 0.952
    * 모델이 전체 데이터의 95.2%를 설명하고 있다는 뜻입니다.
* Adj. R-squared = 0.936
    * R²는 변수가 많아지면 자동으로 올라가므로, 조정된 R²는 변수 수를 보정해줍니다.

⓶ F-statistic와 그 p-value
* F-statistic = 59.41, p = 0.00454
    * F통계 = MSR / MSE
    * 전체 회귀모델이 "통계적으로 유의미한지" 확인하는 지표입니다.
    * p값이 0.05보다 작으므로, "모형 전체가 유의미하다"고 볼 수 있습니다.

⓷ 회귀계수와 t검정
* X(설명 변수)의 coef = 0.426
* X(설명 변수)의 std err = 0.055
    * 0.426이라는 계수 추정값이 ± 0.055 범위 내에서 변동할 수 있다는 의미
* t 통계량 = 7.708 (coef / std err)
    * t통계량에 대한 p value가 0.005로 대립가설 채택
    * 즉, 회귀계수 = 0이 아님

* 제곱근평균제곱오차(RMSE)와 잔차 표준오차(RSE) 차이
    * RSE는 변수(+절편)과 자유도를 고려한 잔차의 표준편차
        * 주로, 선형회귀 모델에서 많이 사용
        * 모델의 복잡성 및 오퍼 피팅 줄이기 위해서 (특히, 예측 변수가 더 많아질 때는)
    * RMSE는 자유도 및 변수 개수 고려 X
        * 모든 예측 모델에서 사용 가능 

* 결정계수
    * R^2 = SSR / SST (= 1 - SSE / SST)
![WEEK_4](../STUDY/image/WEEK_4.png)
    * 변수가 많아지면?
        * 모델이 불필요하게 많은 변수를 포함했을 때 R^2이 타당성없이 증가할 수 있음
        * 방법1: 수정 R 제곱 사용 (레코드수와 모델 변수 개수 고려)
        * 방법2: 부분집합회귀 (최적의 조합을 찾을 순 있지만 계산 비용 많이 듦)
        * 방법3: 단계적회귀
            * 전진제거: 아무것도 없는 상태에서 변수 추가
            * 후진제거: 전체 모델에서 의미없는 변수 제거
        * 방법4: 벌점회귀 
            * 완전 제거 대신, 계수 크기 감소 혹은 0으로 치환

* 교차타당성검사 (=표본외 유효성 검사)
    * R^2, F 통계량, T 통계량 모두 표본 내 유효성 검사
![WEEK4_2](../STUDY/image/WEEK4_2.png)

* 가중회귀
    * "모든 데이터가 똑같이 믿을 만한 건 아니니까, 덜 믿을 수 있는 데이터는 적게 반영하고,더 믿을 수 있는 데이터는 크게 반영하자" 
    * 가중치 = 역분산의 개념
        * 분산이 클수록 오차도 큼
        * 가중치 부여시 = 1/분산
    * 또한, 한 레코드가 여러 관측치를 대표하는 경우에도 높은 가중치를 부여하기 위해 사용 

## 4.3 회귀를 이용한 예측 
* 용어
    * 외삽법: 모델링에 사용된 데이터범위를 벗어난 부분까지 모델 확장 (함부로 사용해서X)
* 회귀 파라미터의 예측구간 by 부트스트랩
    * why1: 적합한 예측변수를 찾고, 계수가 얼마나 불확실한지 알기
    * why2: 개별 데이터값에 존재하는 개별 오차를 찾기 위해

## 4.4 회귀에서의 요인변수 
* 회귀에서는 수치 입력이 필요하기에, 요인변수를 수치화해야 함
    * 일반적 방법은 변수 -> 가변수 집합(더미)로 변환
* 용어
    * 가변수: 0과 1의 이진변수 부호화 
    * 기준 부호화: 한 요인 기준으로 다른 요인이 기준 요인에 따라 비교 되게 만듦
    * 원핫 인코딩: 머신러닝에서 자주 사용. 다중회귀에는 적합X
    * 편차 부호화: 전체 평균에 대한 각 수준을 비교하는 부호화 방법 

* 가변수 표현
    * 원핫인코딩으로 반환
    * 보통, get_dummies() 메서드에서 drop_first=True, 즉 p-1개 열을 반환하여 다중공선성 문제를 피함.

| 인코딩 방식             | 기준 설정         | 계수 해석 방식                              | 사용 목적/적합한 모델                  | 다중공선성 방지 | 주의점/특징                          |
|------------------------|------------------|---------------------------------------------|----------------------------------------|----------------|--------------------------------------|
| 원핫 인코딩 (One-Hot)  | ❌ 기준 없음       | 각 범주는 독립된 열로 표현                  | 머신러닝 모델 (트리계열 등)            | ❌ 없음         | 회귀에서는 `drop_first=True` 권장     |
| 기준 부호화 (Reference) | ✅ 기준 범주 설정   | 기준 그룹과의 차이                          | 선형/로지스틱 회귀                     | ✅ 있음         | 기준 그룹 선택에 따라 해석 달라짐     |
| 편차 부호화 (Effect)   | ✅ 전체 평균 기준   | 전체 평균 대비 각 그룹 효과                 | ANOVA, 그룹 효과 해석                  | ✅ 있음         | 계수 합이 0이 되도록 구성됨           |
| 다항식 부호화 (Polynomial) | ✅ 순서 고려      | 그룹 순서 기반 다항식 방식 인코딩          | 순서형 변수 (예: 학력, 등급 등)        | ✅ 있음         | 순서형 변수에만 의미 있음             |


## 4.5 회귀방정식 해석
* 용어
    * 교란변수: 중요한 예측변수이지만 회귀방정식에 누락되어 결과를 잘못 이끄는 변수 
    * 주효과: 다른 변수와 독립된 하나의 예측변수와 결과변수와의 관계
    * 상호작용: 둘 이상의 예측변수와 응답변수 사이의 상호 의존적 관계 
* 주의
    * 예측변수 간 상관성
    * 다중공선성 
    * 교란변수
    * 상호작용과 주효과
        * 모델에서 어떤 상호작용을 고려해야 할까
            * 사전 지식이나 직관 이용하기
            * 단계적 선택을 이용하여 중요한 변수 고르기
            * 벌점 부여 방식 회귀방법으로 상호작용 가려내기
            * 보통 랜덤 포레스트같은 트리모델로 최적의 상호작용 항을 걸러냄

## 4.6 회귀진단
* 잔차 분석을 통해 회귀 모델 진단함 
* 용어
    * 표준화잔차: 잔차를 표준오차로 나눈 값 
    * 영향값: 회귀모형(특히 회귀계수 추정)에 큰 영향을 주는 관측치
    * 레베리지: 회귀식에 한 레코드가 미치는 영향력 정도
        * 궁금: 레코드가 아니라 단일 입력값(X)이 아닌지? 
    * 이분산성: 어떤 범위 내 출력값 잔차가 매우 높은 분산 보임. 즉, 예측변수를 회귀식이 놓치고 있음을 의미. 
* 영향값
    * 주영향관측값: 회귀 모델에서 제외되었을 때 가장 큰 변화를 가져오는 값 (그렇다고 특잇값은 아님)
        * 회귀에 대한 높은 레베리지를 가진다고 말할 수 있음
    * 측정 방법
        * 햇 값: 이 점이 특이한 위치에 있느냐?
        * 쿡의 거리: 이 점이 회귀선 자체를 얼마나 바꾸는가? (레버리지 + 잔차의 크기의 영향력)
    * 해석 방법
        * 높은 hat value + 큰 잔차 → 쿡의 거리도 큼 → 진짜 영향점
        * 높은 hat value지만 잔차 작음 → 영향은 크지 않음
        * 잔차는 큼 + hat value는 작음 → 이상값(outlier)일 수 있지만 영향은 작음
    * 오차의 비정규성
        * 선형회귀는 잔차가 동일한 분산을 가지고, 정규분포를 따르며 서로 독립적이라는 전제를 둠 
            * 이분산성 ex. 주택 가격에서 회귀 모델은 너무 가격이 낮거나 높은 주택은 예측하지 못한다는 뜻
            * 비정규성
            * 오차 간 상관
        * 오차가 정규분포를 따르지 않는다면 모델의 불완전성 시사
        * 회귀계수에 크게 영향은X 그러나,
            * 다음과 같은 **통계적 추론(inference)**에 필수적인 가정
            * 즉, 형식적 추론에 필요하다는 것

| 목적                        | 정규성이 필요한 이유                                                 |
|-----------------------------|------------------------------------------------------------------------|
| ✅ p-값 계산, t검정, F검정    | 오차가 정규분포를 따라야 검정 통계량의 이론적 분포(정규/t/F)를 따름       |
| ✅ 신뢰구간 정확도           | 오차가 정규분포가 아니면 신뢰구간이 왜곡될 수 있음                      |
| ✅ 예측 구간 계산           | 예측값 주변의 불확실성을 과소 또는 과대평가하게 됨                       |
| ✅ 이상값/영향점 진단       | 정규성 기반 진단 통계량(ex. studentized residuals)이 왜곡될 수 있음     |

## 4.7 다항회귀와 스플라인 회귀
* 용어
    * 다항회귀: 회귀모형에 다항식 항 추가
    * 스플라인 회귀: 다항 구간들을 부드러운 곡선 형태로 피팅 
    * 매듭: 스플라인 구간 구분 값들
    * 일반화가버보형: 자동으로 구간 결정하는 스플라인 모델 
* 스플라인
    * 목적: 고차항 추가 시 바람직하지 않은 흔들림 초래 
        * 흔들림 = 오버피팅이 되어 작은 변동값에도 모델이 불안정해지는 것
    * R에서 bs()함수 사용
        * degree 파라미터는 항수 선택
    * 해석: 선형회귀와 달리 항의 계수가 직접적인 의미를 갖지 않음. 
        * 함수들이 서로 겹치고(중첩되고), 구간별·차수별로 설계되기 때문에, 단일 계수만으로는 x와 y의 국부적 변화율을 읽어낼 수 없음
        * 예측력 제고 + 오버피팅 감소의 효과 있음
* 일반화가법모형: 스플라인 회귀를 자동으로 찾는데 유용 (최적의 매듭점을 찾는 것)