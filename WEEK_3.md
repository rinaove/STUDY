# 3주차
## 3.1 A/B 검정
* 용어
    * 처리군(treatment group)
    * 대조군(control group)

* 처리군 간 차이가 나타나는 이유 
    * 실제 처리의 효과 
    * 임의화 할당에도 효과를 보이는 결과가 처리군에만 집중됨

* 미리 하나의 측정 지표를 결정해야 연구자 편향에 빠지지 않는다.

## 3.2 가설검정
* 왜 가설을 세워야 할까?
    * 임의성을 과소평가하지 않기 위해 
    * 가설을 통해 '이건 우연일 수 있겠다'는 가능성 염두하기
    * 그렇기에, 보통 가설의 가정은 두 변수 간 차이는 우연에 의한 결과라는 것을 염두 = 귀무가설


### 3.2.3 일원/이원 가설검정
* 왜 사용하는가?
    * 방향성을 고려한 대립가설이 필요하기에
* 일원
    * A/B 테스트에 주로 사용 
* 이원
    * R, 파이썬의 scipy 등 여러 소프트웨어에 주로 사용
    * 좀 더 보수적으로 쳐줌 (값이 다르지만, 큰지 작은지 알 수 없을 때)
## 3.3 재표본추출
* 정의
    * 우연인지 아닐지의 확인해보자는 목표를 가지고, 관찰된 데이터의 값에서 표본을 반복적으로 추출
    * 머신러닝 모델 정확성을 향상시키는데도 사용 (ex. 배깅)
    

| 항목            | 배깅 (Bagging)                                   | 부스팅 (Boosting)                                 |
|-----------------|--------------------------------------------------|--------------------------------------------------|
| 학습 방식       | 병렬(parallel), 각 모델은 독립적으로 학습         | 순차적(sequential), 이전 오차를 보완하며 학습     |
| 데이터 샘플링   | 복원추출 (Bootstrap)                             | 동일한 데이터, 가중치 조절                         |
| 모델 간 관계    | 독립적                                            | 의존적 (이전 결과 기반으로 다음 모델 학습)        |
| 목적            | **분산 감소** (과적합 방지)                      | **편향 감소** (성능 개선, 정밀 튜닝)              |
| 대표 알고리즘   | Random Forest                                     | AdaBoost, Gradient Boosting, XGBoost, LightGBM   |
| 과적합 위험     | 적음                                              | 있음 (하지만 튜닝으로 조절 가능)                 |
| 예측 방식       | 평균(회귀) / 다수결(분류)                         | 가중 평균 또는 누적 결과                          |


* 종류
    * 부트스트랩
    * 순열검정


### 3.3.1 순열검정
* 정의
    * 귀무가설이 "두 그룹 간 차이는 단순한 우연"이라고 주장한다면, 그룹 라벨을 섞어서(순열) 얼마나 극단적인 차이가 나올 수 있는지를 측정
    * 즉, 수학적 접근과 다르게 '모두에게 맞는'접근 방식임을 가정 (임의성)
* 방법
    * 여러 그룹 결과를 단일 데이터 집합으로 결합
    * 데이터를 섞은 후, 그룹 A와 동일한 크기의 표본을 비복원 무작위 추출
    * 나머지 데이터에서 그룹 B와 동일한 크기의 표본을 비복원 무작위 추출
    * 추출한 재표본에 대해 다시 계산하고 기록 = 한 번의 순열 반복
* 결과
    * 통계적 유의미성X: 실제 관측된 차이가 순열검정 시 보이는 차이 집합 안에 들어있다면, 관측값은 우연히 일어날 수 있는 것 

* 코드
```
import numpy as np

# 예시 데이터
A = np.array([1, 2, 3])
B = np.array([4, 5, 6])

# 1. 실제 평균 차이
obs_diff = np.mean(B) - np.mean(A)

# 2. 순열 검정
combined = np.concatenate([A, B])
n_perms = 10000
perm_diffs = []

for _ in range(n_perms):
    np.random.shuffle(combined)
    perm_A = combined[:len(A)]
    perm_B = combined[len(A):]
    perm_diffs.append(np.mean(perm_B) - np.mean(perm_A))

# 3. p-value 계산
p_val = np.mean(np.abs(perm_diffs) >= abs(obs_diff))

print(f"Observed difference: {obs_diff:.3f}")
print(f"P-value: {p_val:.4f}")
```

### 3.3.3 전체 및 부트스트랩 순열검정
* 이외에도
    * 전체순열검정: 샘플 크기가 작을 때 무작위로 섞는 것 대신 실제로 나눌 수 있는 모든 조합을 찾음
    * 부트스트랩 순열검정: 무작위 순열검정에서 비복원으로 하던 것을 복원추출로 수행
        * why: 모집단에서 개체 선택 시 임의성 보장

## 3.4 통계적 유의성과 p값
* 통계적 유의성
    * 실험 결과가 우연히 일어난 것인지 아니면 우연히 일어날 수 없는 극단적인 것인지 판단하는 방법
* 1종 오류 (FP)
    * 유의미하지 않는데 유의미하다고 판단
* 2종 오류 (FN)
    * 유의미한데 유의미하지 않는다고 판단
* 모델링에서

| **지표**              | **설명**                                                                                  | **수식**                                                     |
|-----------------------|-------------------------------------------------------------------------------------------|--------------------------------------------------------------|
| **정확도 (Accuracy)**   | 전체 예측 중에서 맞게 예측한 비율                                                       | \(\frac{TP + TN}{TP + TN + FP + FN}\)                       |
| **재현율 (Recall)**     | 실제 긍정 클래스 중에서 모델이 긍정으로 예측한 비율                                     | \(\frac{TP}{TP + FN}\)                                      |
| **정밀도 (Precision)**   | 모델이 긍정으로 예측한 것 중 실제로 긍정인 비율                                         | \(\frac{TP}{TP + FP}\)                                      |
| **F1 Score**           | 정밀도와 재현율의 조화 평균 (정밀도와 재현율의 균형을 맞춘 지표)                         | \(2 \times \frac{Precision \times Recall}{Precision + Recall}\) |

* 이항분포에서는 왜 순열검정을 안하고 p-value를 얻을 수 있나?
    * 이항분포는 모수적 데이터이기에, 순열검정 없이도 p값을 찾아낼 수 있음
    * 즉, 순열검정은 비모수적 방법으로, 분포에 대한 사전 가정 없이 p값을 계산하기 위해 주로 사용

* p값에 대한 논란
    * p값이 유의미하다고 해서 그 자체가 증거가 되지는 않음
    * 진정한 정의는 `랜덤 모델이 주어졌을 때,  그 결과가 관찰된 결과보다 더 극단적인 확률`
    * 그런데, 이 극단적인 확률이 우리 연구에서 유의미하다고 무조건적으로 얘기 가능한가? -> case by case

## 3.5 t검정
* 용어
    * 검정통계량: 관심의 차이 또는 효과에 대한 측정 지표   
    * t 통계량: 평균과 같이 표준화된 형태의 일반적인 검정통계량
* why?
    * t검정은 순열검정의 근사 방법으로, 표본 크기가 충분히 크다면 순열검정에서의 분포가 t-분포에 근사된다는 사실을 발견
    * 즉, 시간을 효율적으로 사용하기 위해 표준적 분포를 참고한다는 것.
    * 대신, 표본 크기가 작을 때 두꺼운 꼬리를 가진 t-분포를 사용

## 3.6 다중검정
* 알파 인플레이션
     * 여러 가지 검정을 동시에 수행할 때 유의수준(알파, α)을 과도하게 적용하여 잘못된 긍정적 결과(1종 오류)를 얻을 확률이 높아지는 현상
* 오버 피팅
    * 모델이 훈련 데이터에 과도하게 적합되어, 훈련 데이터에서 잘 맞지만 새로운 데이터(즉, 테스트 데이터)에 대해 일반화 능력이 떨어지는 현상
        * 모델이 훈련 데이터의 노이즈나 특이값까지 학습하여 불필요한 세부사항까지 반영하는 경우
        * 과도한 모델 복잡성 (너무 많은 피쳐, 파라미터 등등) 경우
    * 더 많은 모델을 사용할수록, 우연에 의해 '유의미하게' 판단되는 것을 방지해야 함
    * 그렇기 때문에, 모델링에서는 홀드아웃 세트를 사용해서 모델이 테스트 세트에서 얼마나 잘 일반화되는지를 확인

## 홀드아웃 세트 종류 표

| **홀드아웃 세트 종류** | **설명**                                                                                       | **특징**                                                      |
|-----------------------|------------------------------------------------------------------------------------------------|---------------------------------------------------------------|
| **단일 홀드아웃 (Single Holdout)** | 데이터셋을 훈련 세트와 테스트 세트로 한 번 나누는 방식. 보통 70% 훈련, 30% 테스트.          | 훈련/테스트 데이터가 한 번만 나뉘므로, 훈련 데이터가 충분하지 않을 수 있음. |
| **k-겹 교차검증 (k-fold Cross Validation)** | 데이터를 k개의 부분으로 나누어, 각 부분을 테스트 세트로 한 번씩 사용하고 나머지 데이터를 훈련 세트로 사용. | 모델 성능을 여러 번 평가할 수 있어 과적합을 방지할 수 있음.         |
| **로우리브 원시 검증 (Leave-One-Out Cross Validation, LOOCV)** | 각 데이터 포인트를 테스트 세트로 사용하고 나머지 데이터를 훈련 세트로 사용하는 방식.        | 데이터가 적을 때 유용하지만, 계산 비용이 많이 듬.                      |
| **층화 샘플링 홀드아웃 (Stratified Holdout)** | 데이터가 불균형할 때, 훈련/테스트 세트를 나누면서 각 세트에서 클래스 비율이 동일하도록 샘플링. | 불균형 데이터셋에서 성능 평가 시 유리한 방식.                           |
| **랜덤 홀드아웃 (Random Holdout)** | 데이터를 무작위로 훈련 세트와 테스트 세트로 나누는 방식.                                        | 데이터의 분포를 잘 반영하려면 여러 번 나누어 평가하는 것이 중요.       |


* 해결방법 by 유의수준 조정
    * 검정횟수에 따라 유의수준 나누기 (p값 조정): 즉, 각 검정에 대해 더 작은 유의수준으로 제한
        * 본페로니 수정: 유의수준 / 검정횟수
        * 투키의 HSD: 각 집단 평균 차이 / 표준오차를 유의수준보다 큰지 비교
            * ANOVA 후 다중 비교에서 그룹 간 평균 차이를 비교할 때 유용 (FP를 방지하기 위해)
* 거짓발견비율 (FDR)
    * 클래스 1 예측 내의 오분류비율 (FP)
    * 일반적으로 대부분 0이고 1은 흥미롭고 드문 경우에서 다룸 (클래스 불균형)


## 3.7 자유도 
* 의의
    * 자유도 모수는 검정에 대한 분포 모양에 영향을 줌
    * 유의성검정 측면에서는 많이 따지지 X. 그러나, `회귀에서 요인변수를 사용할 때 중요`
        * why?
            * 자유도가 많다 -> 피쳐가 늘어남 -> 모델 복잡 -> 과적합
            * n-1을 고려하지 않으면 다중공선성 발생 
                * 자유도 = 독립적으로 변할 수 있는 값의 수이기 때문
                * n-1을 고려하지 않은 자유도의 마지막 변수는 독립적이지 못함
                * 그렇기에, 다중공선성을 피하기 위해 범주형 변수를 n-1 지표 혹은 더미 변수로 요인화


## 3.8 분산분석(ANOVA) 
* 용어
    * 총괄검정: 여러 그룹 평균들의 전체 분산에 대한 단일 가설 검정 (분산분석이 총괄거정에 사용되는 방법임)
    * F통계량: 그룹 평균 간 차이가 랜덤 모델에서 예상되는 것에서 벗어나는 정도를 측정하는 표준화된 통계량
    * SS: 어떤 평균으로부터의 편차들의 제곱합
* why
    * 한 페어씩 비교 횟수가 늘어날수록 임의성에서 패턴을 발견한다고 판단할 일이 늘어나기 때문
* R에서 해석

| Source    | Df | Sum Sq | Mean Sq | F value | Pr(>F)  |
|-----------|----|--------|---------|---------|---------|
| group     | 2  | 620.13 | 310.07  | 17.13   | 0.00036 |
| Residuals | 12 | 217.33 | 18.11   |         |         |

    * Df (Degree of Freedom, 자유도)
    group은 (그룹 수 - 1) → 3-1 = 2
    * Residuals는 (전체 관측치 수 - 그룹 수) → 15-3 = 12
    * Sum Sq (Sum of Squares, 제곱합) 
    그룹 간/내 제곱합
    * Mean Sq (Mean Square, 평균제곱) = 분산
    Mean Sq = Sum Sq ÷ Df
    -> 자유도로 나누는 이유는 그룹 간 크기가 같아도 변동성이 다르기에 정규화하는 것
     * F value (F 통계량)
    F = 그룹간 Mean Sq / 그룹내 Mean Sq
    * Pr(>F) (p-value)
    이 값이 작으면(보통 0.05보다 작으면) 그룹 간 차이가 유의미하다고 판단.

### 3.8.1 F 통계량
* 공식
    * 그룹 간 분산 / 그룹 내 분산
    * 그룹 평균의 분산 / 전차 오차로 인한 분산 
    * R에서는 group의 mean sq / residuals의 mean sq라고 보면 됨
* 왜 이런 공식이?
    * 아노바 검정의 목적은 '두 그룹 이상의 통계적 유의미성을 발견하는 것'
    * 확인하고 싶은 값인 그룹 간 차이가 크고, 변수가 될 수 있는 그룹 내 차이가 작다면 '그룹 간 통계적 유의미성이 있을 가능성이 높은 것'

### 3.8.2 이원 분산분석
* 정의
    * 두 가지 요인이 종속 변수에 미치는 영향을 동시에 분석.
        * 요인 A에 대한 가설
        * 요인 B에 대한 가설
        * 요인A*B의 상호작용에 대한 가설

## 3.9 카이제곱검정 
* R (피어슨 잔차) = (관측값 - 기대값) / 루트 기대값
* 카이제곱통계량 = 각 행열값에 배정된 피어슨 제곱의 합
* 파이썬 코드
```
import numpy as np
from scipy.stats import chi2_contingency

# 광고 A와 B의 클릭 여부를 나타내는 교차표 (2x2 표)
data = np.array([[50, 30],  # Ad A: Clicked, Not Clicked
                 [20, 100]]) # Ad B: Clicked, Not Clicked

# 카이제곱 독립성 검정 수행
chi2, p, dof, expected = chi2_contingency(data)

# 결과 출력
print("Chi-squared Statistic:", chi2)
print("p-value:", p)
print("Degrees of Freedom:", dof)
print("Expected Frequencies:\n", expected)
```

### 3.9.4 데이터 과학에서의 관련성
* 어떨 때 사용
    * 표본 크기가 적절한지 판별할 때 (카이제곱통계량은 관측값과 기대값의 차이를 기반으로 계산되기 때문에, 표본 크기가 크면 기대값이 더 정확하게 추정)
    * 각 독립변수가 실험에 유의미한지 판별

## 3.10 멀티암드 밴딧 알고리즘
* 용어
    * MAD: 다중 처리 실험으로 전통적 통계 접근 실험에서 벗어나 명시적이고 실용적인 실험에 유용
* 왜?
    * 기존 A/B 테스트의 경직성 유연화 
        * A/B 테스트는 실험을 반복하면서 결과를 축적하고 상황에 따른 변화를 반영해야 하는 다중 실험인 경우가 많음
        * 한 번에 여러가지 테스트를 처리하기 위해 사용
    * A, B, C 중 A의 성과가 좋다, BC를 포기하는 것이 아니라 A를 더 많이 시도하는 기회로 변환. C의 성능이 좋아진다면, A의 기회를 C에게 돌리는 등 변수 최소화 및 임의성에 대한 적절한 평가 가능해짐
* 엡실론-그리디 알고리즘
    * 멀티암드 밴딧 알고리즘의 예시
    * 엡실론이 1 (완전 탐험) 기존에 어떤 행동이 좋다는 정보가 없고, 무작위로 행동을 선택하여 모든 가능한 선택을 시도하려는 것임.
    * 엡실론이 0 (완전 개발) 얻은 정보를 바탕으로 가장 좋은 선택을 함. 새로운 행동 시도 없이 기존 정보만으로 행동 선택
    * 그렇기에, 목적에 맞게 최적의 엡실론을 할당해야 함 
    * A/B 테스트 적용시

```
A/B 테스트에서 웹사이트의 버튼 디자인을 비교한다고 가정해 봅시다. 두 가지 버튼 디자인 (A와 B)을 테스트하고, 클릭률을 비교하려고 합니다. 엡실론-그리디 알고리즘을 사용한다면:

탐험 단계 (초기 실험 단계): 실험이 시작될 때, 엡실론 값을 높게 설정하여 A와 B 버튼을 무작위로 선택하면서 각 버튼에 대한 클릭률을 수집합니다. 이때, 엡실론이 0.5라면 50% 확률로 랜덤 버튼을 선택하게 됩니다.

개발 단계 (점차 진행): 시간이 지나면서, 엡실론을 줄여가며 클릭률이 높은 버튼을 더 자주 선택합니다. 예를 들어, 엡실론이 0.1로 줄어들면, 이제는 90% 확률로 클릭률이 높은 버튼을 선택합니다.

최적화 단계 (실험 종료): 충분한 데이터를 얻고 실험을 종료하면, 두 버튼 중 더 나은 클릭률을 보이는 버튼을 최종적으로 선택합니다.
```

* 톰슨의 샘플링
    * 엡실론-그리디 알고리즘보다 더 복잡 

## 3.11 검정력과 표본 크기
* 용어
    * 효과 크기: 통계 검정을 통해 판단 가능한 효과의 최소 크기
    * 검정력: 주어진 표본 크기로 효과 크기를 알아낼 확률
* 검정력 추정을 하는 이유
    * 최소한의 효과 크기를 위한 표본 크기를 알아내기 위해
* 그래서 보통 가설검정을 할 때는 4개 중 최소 3가지 필요
    * 표본 크기
    * 최소한의 효과 크기
    * 유의수준
    * 검정력 